{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering the player ratings data - File in early stages"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Functions in file from: https://www.tensorflow.org/recommenders/examples/basic_retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scanning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.manifold\n",
    "import seaborn as sns\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Altair and activate its colab renderer.\n",
    "print(\"Installing Altair...\")\n",
    "!pip install git+git://github.com/altair-viz/altair.git -q\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "alt.renderers.enable('colab')\n",
    "print(\"Done installing Altair.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask(df, key, function):\n",
    "  \"\"\"Returns a filtered dataframe, by applying function to key\"\"\"\n",
    "  return df[function(df[key])]\n",
    "\n",
    "def flatten_cols(df):\n",
    "  df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.mask = mask\n",
    "pd.DataFrame.flatten_cols = flatten_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.disable_v2_behavior()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('player_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ratings = pd.pivot_table(df, index=['user'], values=['rating'], aggfunc='count')\n",
    "num_ratings.reset_index(inplace=True)\n",
    "num_ratings.columns = ['user','ratings']\n",
    "num_ratings.sort_values('ratings', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ratings[num_ratings['ratings'] > -1].shape[0], num_ratings[num_ratings['ratings'] > 10].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df[df['user'] == 'stoneart69'], x = 'rating')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tough crowd!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating_int'] = df['rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data = df, x = 'rating_int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['approve'] = np.where(df['rating'] >= 7, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility to split the data into training and test sets.\n",
    "def split_dataframe(df, holdout_fraction=0.1):\n",
    "  \"\"\"Splits a DataFrame into training and test sets.\n",
    "  Args:\n",
    "    df: a dataframe.\n",
    "    holdout_fraction: fraction of dataframe rows to use in the test set.\n",
    "  Returns:\n",
    "    train: dataframe for training\n",
    "    test: dataframe for testing\n",
    "  \"\"\"\n",
    "  test = df.sample(frac=holdout_fraction, replace=False)\n",
    "  train = df[~df.index.isin(test.index)]\n",
    "  return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = df.merge(num_ratings, on ='user')\n",
    "ratings = ratings[ratings['ratings'] > 10]\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def return_negative_one():\n",
    "    return -1\n",
    "    \n",
    "user_dict = defaultdict(return_negative_one)\n",
    "game_dict = defaultdict(return_negative_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for u in ratings['user'].unique():\n",
    "    user_dict[u] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for u in ratings['game_id'].unique():\n",
    "    game_dict[u] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['user_idx'] = ratings['user'].apply(lambda x: user_dict[x])\n",
    "ratings['game_idx'] = ratings['game_id'].apply(lambda x: game_dict[x])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.shape[0], ratings['user_idx'].max(), ratings['user_idx'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Solution\n",
    "def build_rating_sparse_tensor(ratings_df):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    ratings_df: a pd.DataFrame with `user_id`, `movie_id` and `rating` columns.\n",
    "  Returns:\n",
    "    a tf.SparseTensor representing the ratings matrix.\n",
    "  \"\"\"\n",
    "  indices = ratings_df[['user_idx', 'game_idx']].values\n",
    "  values_ = ratings_df['rating_int'].values\n",
    "  return tf.SparseTensor(\n",
    "      indices=indices,\n",
    "      values=values_,\n",
    "      dense_shape=[ratings_df['user_idx'].nunique(), ratings_df['game_idx'].nunique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_mean_square_error(sparse_ratings, user_embeddings, movie_embeddings):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    sparse_ratings: A SparseTensor rating matrix, of dense_shape [N, M]\n",
    "    user_embeddings: A dense Tensor U of shape [N, k] where k is the embedding\n",
    "      dimension, such that U_i is the embedding of user i.\n",
    "    movie_embeddings: A dense Tensor V of shape [M, k] where k is the embedding\n",
    "      dimension, such that V_j is the embedding of movie j.\n",
    "  Returns:\n",
    "    A scalar Tensor representing the MSE between the true ratings and the\n",
    "      model's predictions.\n",
    "  \"\"\"\n",
    "  predictions = tf.gather_nd(\n",
    "      tf.matmul(user_embeddings, movie_embeddings, transpose_b=True),\n",
    "      sparse_ratings.indices)\n",
    "  loss = tf.losses.mean_squared_error(sparse_ratings.values, predictions)\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFModel(object):\n",
    "  \"\"\"Simple class that represents a collaborative filtering model\"\"\"\n",
    "  def __init__(self, embedding_vars, loss, metrics=None):\n",
    "    \"\"\"Initializes a CFModel.\n",
    "    Args:\n",
    "      embedding_vars: A dictionary of tf.Variables.\n",
    "      loss: A float Tensor. The loss to optimize.\n",
    "      metrics: optional list of dictionaries of Tensors. The metrics in each\n",
    "        dictionary will be plotted in a separate figure during training.\n",
    "    \"\"\"\n",
    "    self._embedding_vars = embedding_vars\n",
    "    self._loss = loss\n",
    "    self._metrics = metrics\n",
    "    self._embeddings = {k: None for k in embedding_vars}\n",
    "    self._session = None\n",
    "\n",
    "  @property\n",
    "  def embeddings(self):\n",
    "    \"\"\"The embeddings dictionary.\"\"\"\n",
    "    return self._embeddings\n",
    "\n",
    "  def train(self, num_iterations=100, learning_rate=1.0, plot_results=True,\n",
    "            optimizer=tf.train.GradientDescentOptimizer):\n",
    "    \"\"\"Trains the model.\n",
    "    Args:\n",
    "      iterations: number of iterations to run.\n",
    "      learning_rate: optimizer learning rate.\n",
    "      plot_results: whether to plot the results at the end of training.\n",
    "      optimizer: the optimizer to use. Default to GradientDescentOptimizer.\n",
    "    Returns:\n",
    "      The metrics dictionary evaluated at the last iteration.\n",
    "    \"\"\"\n",
    "    with self._loss.graph.as_default():\n",
    "      opt = optimizer(learning_rate)\n",
    "      train_op = opt.minimize(self._loss)\n",
    "      local_init_op = tf.group(\n",
    "          tf.variables_initializer(opt.variables()),\n",
    "          tf.local_variables_initializer())\n",
    "      if self._session is None:\n",
    "        self._session = tf.Session()\n",
    "        with self._session.as_default():\n",
    "          self._session.run(tf.global_variables_initializer())\n",
    "          self._session.run(tf.tables_initializer())\n",
    "          tf.train.start_queue_runners()\n",
    "\n",
    "    with self._session.as_default():\n",
    "      local_init_op.run()\n",
    "      iterations = []\n",
    "      metrics = self._metrics or ({},)\n",
    "      metrics_vals = [collections.defaultdict(list) for _ in self._metrics]\n",
    "\n",
    "      # Train and append results.\n",
    "      for i in range(num_iterations + 1):\n",
    "        _, results = self._session.run((train_op, metrics))\n",
    "        if (i % 10 == 0) or i == num_iterations:\n",
    "          print(\"\\r iteration %d: \" % i + \", \".join(\n",
    "                [\"%s=%f\" % (k, v) for r in results for k, v in r.items()]),\n",
    "                end='')\n",
    "          iterations.append(i)\n",
    "          for metric_val, result in zip(metrics_vals, results):\n",
    "            for k, v in result.items():\n",
    "              metric_val[k].append(v)\n",
    "\n",
    "      for k, v in self._embedding_vars.items():\n",
    "        self._embeddings[k] = v.eval()\n",
    "\n",
    "      if plot_results:\n",
    "        # Plot the metrics.\n",
    "        num_subplots = len(metrics)+1\n",
    "        fig = plt.figure()\n",
    "        fig.set_size_inches(num_subplots*10, 8)\n",
    "        for i, metric_vals in enumerate(metrics_vals):\n",
    "          ax = fig.add_subplot(1, num_subplots, i+1)\n",
    "          for k, v in metric_vals.items():\n",
    "            ax.plot(iterations, v, label=k)\n",
    "          ax.set_xlim([1, num_iterations])\n",
    "          ax.legend()\n",
    "      return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(ratings, embedding_dim=3, init_stddev=1.):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "    ratings: a DataFrame of the ratings\n",
    "    embedding_dim: the dimension of the embedding vectors.\n",
    "    init_stddev: float, the standard deviation of the random initial embeddings.\n",
    "  Returns:\n",
    "    model: a CFModel.\n",
    "  \"\"\"\n",
    "  # Split the ratings DataFrame into train and test.\n",
    "  train_ratings, test_ratings = split_dataframe(ratings)\n",
    "  # SparseTensor representation of the train and test datasets.\n",
    "  A_train = build_rating_sparse_tensor(train_ratings)\n",
    "  A_test = build_rating_sparse_tensor(test_ratings)\n",
    "  # Initialize the embeddings using a normal distribution.\n",
    "  U = tf.Variable(tf.random_normal(\n",
    "      [A_train.dense_shape[0], embedding_dim], stddev=init_stddev))\n",
    "  V = tf.Variable(tf.random_normal(\n",
    "      [A_train.dense_shape[1], embedding_dim], stddev=init_stddev))\n",
    "  train_loss = sparse_mean_square_error(A_train, U, V)\n",
    "  test_loss = sparse_mean_square_error(A_test, U, V)\n",
    "  metrics = {\n",
    "      'train_error': train_loss,\n",
    "      'test_error': test_loss\n",
    "  }\n",
    "  embeddings = {\n",
    "      \"user_idx\": U,\n",
    "      \"game_idx\": V\n",
    "  }\n",
    "  return CFModel(embeddings, train_loss, [metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings, test_ratings = split_dataframe(ratings)\n",
    "# SparseTensor representation of the train and test datasets.\n",
    "A_train = build_rating_sparse_tensor(train_ratings)\n",
    "A_test = build_rating_sparse_tensor(test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CF model and train it.\n",
    "model = build_model(ratings, embedding_dim=10, init_stddev=0.5)\n",
    "model.train(num_iterations=350, learning_rate=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CF model and train it.\n",
    "model = build_model(ratings, embedding_dim=3, init_stddev=0.1)\n",
    "model.train(num_iterations=350, learning_rate=10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Recommender Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#itle Solution\n",
    "DOT = 'dot'\n",
    "COSINE = 'cosine'\n",
    "def compute_scores(query_embedding, item_embeddings, measure=DOT):\n",
    "  \"\"\"Computes the scores of the candidates given a query.\n",
    "  Args:\n",
    "    query_embedding: a vector of shape [k], representing the query embedding.\n",
    "    item_embeddings: a matrix of shape [N, k], such that row i is the embedding\n",
    "      of item i.\n",
    "    measure: a string specifying the similarity measure to be used. Can be\n",
    "      either DOT or COSINE.\n",
    "  Returns:\n",
    "    scores: a vector of shape [N], such that scores[i] is the score of item i.\n",
    "  \"\"\"\n",
    "  u = query_embedding\n",
    "  V = item_embeddings\n",
    "  if measure == COSINE:\n",
    "    V = V / np.linalg.norm(V, axis=1, keepdims=True)\n",
    "    u = u / np.linalg.norm(u)\n",
    "  scores = u.dot(V.T)\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect('bgg.db')\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = cur.execute('SELECT * FROM TOP_GAMES_FULL')\n",
    "results = cur.execute('PRAGMA table_info(TOP_GAMES_FULL)')\n",
    "results = results.fetchall()\n",
    "result_li = [r for r in results]\n",
    "column_li = []\n",
    "for r in result_li:\n",
    "    column_li.append(r[1])\n",
    "\n",
    "print(column_li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cur.execute('SELECT * FROM TOP_GAMES_FULL')\n",
    "results = results.fetchall()\n",
    "result_li = [r for r in results]\n",
    "df = pd.DataFrame(result_li, columns = column_li)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['game_idx'] = df['id'].apply(lambda x: game_dict[int(x)])\n",
    "games = df[df['game_idx'] >= 0]\n",
    "games = games[['game_idx', 'title', 'year', 'weight', 'play_time', 'ratings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_neighbors(model, title_substring, measure=DOT, k=6):\n",
    "  # Search for movie ids that match the given substring.\n",
    "  ids =  games.loc[games['title'].str.contains(title_substring), ['game_idx']].values\n",
    "  ids = list(ids.flatten())\n",
    "  titles = games.loc[games['game_idx'].isin(ids), 'title'].values\n",
    "  if len(titles) == 0:\n",
    "    raise ValueError(\"Found no games with title %s\" % title_substring)\n",
    "  print(\"Nearest neighbors of : %s.\" % titles[0])\n",
    "  if len(titles) > 1:\n",
    "    print(\"[Found more than one matching game. Other candidates: {}]\".format(\n",
    "        \", \".join(titles[1:])))\n",
    "  movie_id = ids[0]\n",
    "  scores = compute_scores(\n",
    "      model.embeddings[\"game_idx\"][movie_id], model.embeddings[\"game_idx\"],\n",
    "      measure)\n",
    "  score_key = measure + ' score'\n",
    "  df = pd.DataFrame({\n",
    "      score_key: list(scores),\n",
    "      'titles': games['title']\n",
    "      #'genres': movies['all_genres']\n",
    "  })\n",
    "  display.display(df.sort_values([score_key], ascending=False).head(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_neighbors(model, \"bohnanza\", COSINE, k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_neighbors(model, \"orleans\", DOT, k= 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot product recommends the same games no matter what. Cosine seems to perform much better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_embedding_norm(models):\n",
    "  \"\"\"Visualizes the norm and number of ratings of the movie embeddings.\n",
    "  Args:\n",
    "    model: A MFModel object.\n",
    "  \"\"\"\n",
    "  if not isinstance(models, list):\n",
    "    models = [models]\n",
    "  df = pd.DataFrame({\n",
    "      'title': games['title'],\n",
    "      'num_ratings': games['user_ratings'],\n",
    "  })\n",
    "  df['num_ratings'] = df['num_ratings'].astype(int)\n",
    "  #df['num_ratings'] = df['num_ratings'].apply(lambda x: np.log(x))\n",
    "  charts = []\n",
    "  brush = alt.selection_interval()\n",
    "  for i, model in enumerate(models):\n",
    "    norm_key = 'norm'+str(i)\n",
    "    df[norm_key] = np.linalg.norm(model.embeddings[\"game_idx\"], axis=1)\n",
    "    nearest = alt.selection(\n",
    "        type='single', encodings=['x', 'y'], on='mouseover', nearest=True,\n",
    "        empty='none')\n",
    "    base = alt.Chart().mark_circle().encode(\n",
    "        x='num_ratings',\n",
    "        y=norm_key,\n",
    "        color=alt.condition(brush, alt.value('#4c78a8'), alt.value('lightgray'))\n",
    "    ).properties(\n",
    "        selection=nearest).add_selection(brush)\n",
    "    text = alt.Chart().mark_text(align='center', dx=5, dy=-5).encode(\n",
    "        x='num_ratings', y=norm_key,\n",
    "        text=alt.condition(nearest, 'title', alt.value('')))\n",
    "    charts.append(alt.layer(base, text))\n",
    "  return alt.hconcat(*charts, data=df), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'user_ratings' in games.columns:\n",
    "    num_of_game_ratings = pd.pivot_table(data=ratings, index = ['game_idx'], values = ['user'], aggfunc='count')\n",
    "    num_of_game_ratings.reset_index(inplace=True)\n",
    "    num_of_game_ratings.columns = ['game_idx', 'user_ratings']\n",
    "    games = games.merge(num_of_game_ratings, on = 'game_idx')\n",
    "    games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing, _ = game_embedding_norm(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cur.execute('''\n",
    "WITH inner_query AS (\n",
    "SELECT id, category, ROW_NUMBER() OVER (PARTITION BY id)  r\n",
    "\n",
    "FROM BGG_CATEGORIES)\n",
    "\n",
    "SELECT id game_id, category\n",
    "\n",
    "FROM inner_query\n",
    "\n",
    "WHERE 1=1\n",
    "    --AND r = 1\n",
    "\n",
    "''')\n",
    "results = results.fetchall()\n",
    "result_li = [r for r in results]\n",
    "game_genres = pd.DataFrame(result_li, columns = ['game_id', 'genre'])\n",
    "game_genres['game_idx'] = game_genres['game_id'].apply(lambda x: game_dict[int(x)])\n",
    "game_genres = game_genres[game_genres['game_idx'] > -1]\n",
    "game_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_genre_list = pd.pivot_table(data=game_genres,\n",
    "               index = ['game_idx'],\n",
    "               values=['genre'],\n",
    "               aggfunc = lambda x: ';'.join(x)).reset_index()\n",
    "full_genre_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_genres = pd.pivot_table(game_genres\n",
    "                ,index=['genre']\n",
    "                ,values = ['game_idx']\n",
    "                ,aggfunc='count').sort_values('game_idx',\n",
    "                                            ascending=False,).head(10).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_genres['Top'] = game_genres['genre'].isin(top_10_genres).astype(int)\n",
    "game_genres.sort_values(['game_id','Top'], ascending=[True, False], inplace=True)\n",
    "game_genres.drop_duplicates(subset=['game_id'], keep='first', inplace=True)\n",
    "game_genres.loc[game_genres['Top'] == 0, 'genre'] = 'Other'\n",
    "del game_genres['Top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del games['genre']\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = games.merge(game_genres, on = ['game_idx'], how='left')\n",
    "games.drop(columns = ['game_id_x', 'game_id_y'], inplace=True)\n",
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.loc[pd.isna(games['genre']), 'genre'] = 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_filter = alt.selection_multi(fields=['genre'])\n",
    "genre_chart = alt.Chart().mark_bar().encode(\n",
    "    x=\"count()\",\n",
    "    y=alt.Y('genre'),\n",
    "    color=alt.condition(\n",
    "        genre_filter,\n",
    "        alt.Color(\"genre:N\"),\n",
    "        alt.value('lightgray'))\n",
    ").properties(height=300, selection=genre_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_game_embeddings(data, x, y):\n",
    "  nearest = alt.selection(\n",
    "      type='single', encodings=['x', 'y'], on='mouseover', nearest=True,\n",
    "      empty='none')\n",
    "  base = alt.Chart().mark_circle().encode(\n",
    "      x=x,\n",
    "      y=y,\n",
    "      color=alt.condition(genre_filter, \"genre\", alt.value(\"whitesmoke\")),\n",
    "  ).properties(\n",
    "      width=600,\n",
    "      height=600,\n",
    "      selection=nearest)\n",
    "  text = alt.Chart().mark_text(align='left', dx=5, dy=-5).encode(\n",
    "      x=x,\n",
    "      y=y,\n",
    "      text=alt.condition(nearest, 'title', alt.value('')))\n",
    "  return alt.hconcat(alt.layer(base, text), genre_chart, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_game_embeddings(model):\n",
    "  \"\"\"Visualizes the movie embeddings, projected using t-SNE with Cosine measure.\n",
    "  Args:\n",
    "    model: A MFModel object.\n",
    "  \"\"\"\n",
    "  tsne = sklearn.manifold.TSNE(\n",
    "      n_components=2, perplexity=40, metric='cosine', early_exaggeration=10.0,\n",
    "      init='pca', verbose=True, n_iter=400)\n",
    "\n",
    "  print('Running t-SNE...')\n",
    "  V_proj = tsne.fit_transform(model.embeddings[\"game_idx\"])\n",
    "  print('ARRAY SIZES')\n",
    "  #print(len(games.loc[:,'x']), len(V_proj[:, 0]))  \n",
    "    \n",
    "  games.loc[:,'x'] = V_proj[:, 0]\n",
    "  games.loc[:,'y'] = V_proj[:, 1]\n",
    "  return visualize_game_embeddings(games, 'x', 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_game_embeddings(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lowinit = build_model(ratings, embedding_dim=3, init_stddev=0.25)\n",
    "# model_lowinit.train(num_iterations=100, learning_rate=20.)\n",
    "# movie_neighbors(model_lowinit, \"gloomhaven\", DOT)\n",
    "# movie_neighbors(model_lowinit, \"gloomhaven\", COSINE)\n",
    "# movie_embedding_norm([model, model_lowinit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_games = (ratings[[\"user_idx\", \"game_idx\"]]\n",
    "                .groupby(\"user_idx\", as_index=False)\n",
    "                .aggregate(lambda x: list(x)))\n",
    "rated_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games['year'] = games['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = games.merge(full_genre_list, on = ['game_idx'], how= 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.rename(columns = {'genre_x': 'genre', 'genre_y': 'all_genres'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games['all_genres'].fillna('NA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games['year'] = games['year'].astype(str)\n",
    "games['game_idx'] = games['game_idx'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game_idx         object\n",
       "title            object\n",
       "year             object\n",
       "weight           object\n",
       "play_time        object\n",
       "ratings          object\n",
       "user_ratings      int64\n",
       "x               float32\n",
       "y               float32\n",
       "game_id          object\n",
       "genre            object\n",
       "all_genres       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title Batch generation code (run this cell)\n",
    "years_dict = {\n",
    "    game: year for game, year in zip(games[\"game_idx\"], games[\"year\"])\n",
    "}\n",
    "genres_dict = {\n",
    "#     game: genres.split(';')\n",
    "#     for game, genres in zip(games[\"game_idx\"], games[\"genre\"])\n",
    "    game : year for game, year in zip(games[\"game_idx\"], games[\"genre\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(ratings, batch_size):\n",
    "  \"\"\"Creates a batch of examples.\n",
    "  Args:\n",
    "    ratings: A DataFrame of ratings such that examples[\"movie_id\"] is a list of\n",
    "      movies rated by a user.\n",
    "    batch_size: The batch size.\n",
    "  \"\"\"\n",
    "  def pad(x, fill):\n",
    "    print(\"padding\")\n",
    "    return pd.DataFrame.from_dict(x).fillna(fill).values\n",
    "\n",
    "  game = []\n",
    "  year = []\n",
    "  genre = []\n",
    "  label = []\n",
    "  for game_ids in ratings[\"game_idx\"].values:\n",
    "    game.append(game_ids)\n",
    "    #genre.append([x for game_id in game_ids for x in genres_dict[str(game_id)]])\n",
    "    genre.append([genres_dict[str(game_id)] for game_id in game_ids])\n",
    "    year.append([years_dict[str(game_id)] for game_id in game_ids])\n",
    "    label.append([int(game_id) for game_id in game_ids])\n",
    "  print('finished intital loop')\n",
    "\n",
    "    \n",
    "  features = {\n",
    "      \"game_id\": pad(game, \"\"),\n",
    "      \"year\": pad(year, \"\"),\n",
    "      \"genre\": pad(genre, \"\"),\n",
    "      \"label\": pad(label, -1)\n",
    "  }\n",
    "  print('created features', features.shape)\n",
    "  batch = (\n",
    "      tf.data.Dataset.from_tensor_slices(features)\n",
    "      .shuffle(1000)\n",
    "      .repeat()\n",
    "      .batch(batch_size)\n",
    "      .make_one_shot_iterator()\n",
    "      .get_next())\n",
    "  return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random(x):\n",
    "  \"\"\"Selectes a random elements from each row of x.\"\"\"\n",
    "  def to_float(x):\n",
    "    return tf.cast(x, tf.float32)\n",
    "  def to_int(x):\n",
    "    return tf.cast(x, tf.int64)\n",
    "  batch_size = tf.shape(x)[0]\n",
    "  rn = tf.range(batch_size)\n",
    "  nnz = to_float(tf.count_nonzero(x >= 0, axis=1))\n",
    "  rnd = tf.random_uniform([batch_size])\n",
    "  ids = tf.stack([to_int(rn), to_int(nnz * rnd)], axis=1)\n",
    "  return to_int(tf.gather_nd(x, ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_loss(user_embeddings, game_embeddings, labels):\n",
    "  \"\"\"Returns the cross-entropy loss of the softmax model.\n",
    "  Args:\n",
    "    user_embeddings: A tensor of shape [batch_size, embedding_dim].\n",
    "    movie_embeddings: A tensor of shape [num_movies, embedding_dim].\n",
    "    labels: A tensor of [batch_size], such that labels[i] is the target label\n",
    "      for example i.\n",
    "  Returns:\n",
    "    The mean cross-entropy loss.\n",
    "  \"\"\"\n",
    "  # Verify that the embddings have compatible dimensions\n",
    "  user_emb_dim = user_embeddings.shape[1].value\n",
    "  game_emb_dim = game_embeddings.shape[1].value\n",
    "  if user_emb_dim != movie_emb_dim:\n",
    "    raise ValueError(\n",
    "        \"The user embedding dimension %d should match the movie embedding \"\n",
    "        \"dimension % d\" % (user_emb_dim, movie_emb_dim))\n",
    "\n",
    "  logits = tf.matmul(user_embeddings, game_embeddings, transpose_b=True)\n",
    "  loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "      logits=logits, labels=labels))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_softmax_model(rated_games, embedding_cols, hidden_dims):\n",
    "  \"\"\"Builds a Softmax model for gameLens.\n",
    "  Args:\n",
    "    rated_games: DataFrame of traing examples.\n",
    "    embedding_cols: A dictionary mapping feature names (string) to embedding\n",
    "      column objects. This will be used in tf.feature_column.input_layer() to\n",
    "      create the input layer.\n",
    "    hidden_dims: int list of the dimensions of the hidden layers.\n",
    "  Returns:\n",
    "    A CFModel object.\n",
    "  \"\"\"\n",
    "  def create_network(features):\n",
    "    \"\"\"Maps input features dictionary to user embeddings.\n",
    "    Args:\n",
    "      features: A dictionary of input string tensors.\n",
    "    Returns:\n",
    "      outputs: A tensor of shape [batch_size, embedding_dim].\n",
    "    \"\"\"\n",
    "    # Create a bag-of-words embedding for each sparse feature.\n",
    "    inputs = tf.feature_column.input_layer(features, embedding_cols)\n",
    "    # Hidden layers.\n",
    "    input_dim = inputs.shape[1].value\n",
    "    for i, output_dim in enumerate(hidden_dims):\n",
    "      w = tf.get_variable(\n",
    "          \"hidden%d_w_\" % i, shape=[input_dim, output_dim],\n",
    "          initializer=tf.truncated_normal_initializer(\n",
    "              stddev=1./np.sqrt(output_dim))) / 10.\n",
    "      outputs = tf.matmul(inputs, w)\n",
    "      input_dim = output_dim\n",
    "      inputs = outputs\n",
    "    return outputs\n",
    "\n",
    "  train_rated_games, test_rated_games = split_dataframe(rated_games)\n",
    "  train_batch = make_batch(train_rated_games, 200)\n",
    "  test_batch = make_batch(test_rated_games, 100)\n",
    "\n",
    "  with tf.variable_scope(\"model\", reuse=False):\n",
    "    # Train\n",
    "    train_user_embeddings = create_network(train_batch)\n",
    "    train_labels = select_random(train_batch[\"label\"])\n",
    "  with tf.variable_scope(\"model\", reuse=True):\n",
    "    # Test\n",
    "    test_user_embeddings = create_network(test_batch)\n",
    "    test_labels = select_random(test_batch[\"label\"])\n",
    "    game_embeddings = tf.get_variable(\n",
    "        \"input_layer/game_id_embedding/embedding_weights\")\n",
    "\n",
    "  test_loss = softmax_loss(\n",
    "      test_user_embeddings, game_embeddings, test_labels)\n",
    "  train_loss = softmax_loss(\n",
    "      train_user_embeddings, game_embeddings, train_labels)\n",
    "  _, test_precision_at_10 = tf.metrics.precision_at_k(\n",
    "      labels=test_labels,\n",
    "      predictions=tf.matmul(test_user_embeddings, game_embeddings, transpose_b=True),\n",
    "      k=10)\n",
    "\n",
    "  metrics = (\n",
    "      {\"train_loss\": train_loss, \"test_loss\": test_loss},\n",
    "      {\"test_precision_at_10\": test_precision_at_10}\n",
    "  )\n",
    "  embeddings = {\"game_idx\": game_embeddings}\n",
    "  return CFModel(embeddings, train_loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create feature embedding columns\n",
    "def make_embedding_col(key, embedding_dim):\n",
    "  categorical_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "      key=key, vocabulary_list=list(set(games[key].values)), num_oov_buckets=0)\n",
    "  return tf.feature_column.embedding_column(\n",
    "      categorical_column=categorical_col, dimension=embedding_dim,\n",
    "      # default initializer: trancated normal with stddev=1/sqrt(dimension)\n",
    "      combiner='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished intital loop\n",
      "padding\n"
     ]
    }
   ],
   "source": [
    "ratings['game_idx'] = ratings['game_idx'].astype(str)\n",
    "with tf.Graph().as_default():\n",
    "  softmax_model = build_softmax_model(\n",
    "      rated_games,\n",
    "      embedding_cols=[\n",
    "          make_embedding_col(\"game_idx\", 10),\n",
    "          make_embedding_col(\"genre\", 3),\n",
    "          make_embedding_col(\"year\", 2),\n",
    "      ],\n",
    "      hidden_dims=[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_model.train(\n",
    "    learning_rate=8., num_iterations=300, optimizer=tf.train.AdagradOptimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
